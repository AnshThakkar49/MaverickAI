{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55c318fc-16e2-4fc2-bf5e-d351228aa10a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Disease            S1             S2             S3  \\\n",
      "0  Diabetes        fatigue    weight_loss   restlessness   \n",
      "1  Diabetes        fatigue    weight_loss   restlessness   \n",
      "2  Diabetes    weight_loss   restlessness       lethargy   \n",
      "3  Diabetes        fatigue   restlessness       lethargy   \n",
      "4  Diabetes        fatigue    weight_loss       lethargy   \n",
      "\n",
      "                       S4                             S5  Unnamed: 6  \\\n",
      "0                lethargy          irregular_sugar_level         NaN   \n",
      "1                lethargy          irregular_sugar_level         NaN   \n",
      "2   irregular_sugar_level   blurred_and_distorted_vision         NaN   \n",
      "3   irregular_sugar_level   blurred_and_distorted_vision         NaN   \n",
      "4   irregular_sugar_level   blurred_and_distorted_vision         NaN   \n",
      "\n",
      "   Unnamed: 7  Unnamed: 8  Unnamed: 9  Unnamed: 10 Unnamed: 11 Unnamed: 12  \\\n",
      "0         NaN         NaN         NaN          NaN         NaN         NaN   \n",
      "1         NaN         NaN         NaN          NaN         NaN         NaN   \n",
      "2         NaN         NaN         NaN          NaN         NaN         NaN   \n",
      "3         NaN         NaN         NaN          NaN         NaN         NaN   \n",
      "4         NaN         NaN         NaN          NaN         NaN         NaN   \n",
      "\n",
      "  Unnamed: 13 Unnamed: 14 Unnamed: 15 Unnamed: 16 Unnamed: 17  \n",
      "0         NaN         NaN         NaN         NaN         NaN  \n",
      "1         NaN         NaN         NaN         NaN         NaN  \n",
      "2         NaN         NaN         NaN         NaN         NaN  \n",
      "3         NaN         NaN         NaN         NaN         NaN  \n",
      "4         NaN         NaN         NaN         NaN         NaN  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 60 entries, 0 to 59\n",
      "Data columns (total 18 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Disease      60 non-null     object \n",
      " 1   S1           60 non-null     object \n",
      " 2   S2           60 non-null     object \n",
      " 3   S3           60 non-null     object \n",
      " 4   S4           60 non-null     object \n",
      " 5   S5           60 non-null     object \n",
      " 6   Unnamed: 6   0 non-null      float64\n",
      " 7   Unnamed: 7   0 non-null      float64\n",
      " 8   Unnamed: 8   0 non-null      float64\n",
      " 9   Unnamed: 9   0 non-null      float64\n",
      " 10  Unnamed: 10  0 non-null      float64\n",
      " 11  Unnamed: 11  21 non-null     object \n",
      " 12  Unnamed: 12  20 non-null     object \n",
      " 13  Unnamed: 13  20 non-null     object \n",
      " 14  Unnamed: 14  11 non-null     object \n",
      " 15  Unnamed: 15  10 non-null     object \n",
      " 16  Unnamed: 16  10 non-null     object \n",
      " 17  Unnamed: 17  2 non-null      object \n",
      "dtypes: float64(5), object(13)\n",
      "memory usage: 8.6+ KB\n",
      "None\n",
      "Disease         0\n",
      "S1              0\n",
      "S2              0\n",
      "S3              0\n",
      "S4              0\n",
      "S5              0\n",
      "Unnamed: 6     60\n",
      "Unnamed: 7     60\n",
      "Unnamed: 8     60\n",
      "Unnamed: 9     60\n",
      "Unnamed: 10    60\n",
      "Unnamed: 11    39\n",
      "Unnamed: 12    40\n",
      "Unnamed: 13    40\n",
      "Unnamed: 14    49\n",
      "Unnamed: 15    50\n",
      "Unnamed: 16    50\n",
      "Unnamed: 17    58\n",
      "dtype: int64\n",
      "Non-numeric columns: ['Disease', 'S1', 'S2', 'S3', 'S4', 'S5']\n",
      "3    6\n",
      "4    6\n",
      "5    6\n",
      "0    6\n",
      "2    6\n",
      "1    6\n",
      "Name: Disease, dtype: int64\n",
      "Missing features: []\n",
      "Training set class distribution:\n",
      "0    5\n",
      "1    5\n",
      "5    5\n",
      "2    5\n",
      "4    4\n",
      "3    4\n",
      "Name: Disease, dtype: int64\n",
      "Test set class distribution:\n",
      "4    2\n",
      "3    2\n",
      "5    1\n",
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "Name: Disease, dtype: int64\n",
      "Accuracy: 0.75\n",
      "Confusion Matrix:\n",
      "[[1 0 0 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 1 0 0 0]\n",
      " [1 0 0 1 0 0]\n",
      " [0 0 1 0 1 0]\n",
      " [0 0 0 0 0 1]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67         1\n",
      "           1       1.00      1.00      1.00         1\n",
      "           2       0.50      1.00      0.67         1\n",
      "           3       1.00      0.50      0.67         2\n",
      "           4       1.00      0.50      0.67         2\n",
      "           5       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.75         8\n",
      "   macro avg       0.83      0.83      0.78         8\n",
      "weighted avg       0.88      0.75      0.75         8\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['logistic_regression_model.pkl']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import joblib\n",
    "\n",
    "# Step 1: Load the CSV file\n",
    "data = pd.read_csv('BIOBOT_DATASET (1).csv')\n",
    "\n",
    "# Step 2: Inspect the data\n",
    "print(data.head())\n",
    "print(data.info())\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Step 3: Handle missing values and remove duplicates\n",
    "# Drop columns with any missing values\n",
    "data = data.dropna(axis=1)\n",
    "\n",
    "# Drop rows with missing values\n",
    "data = data.dropna()\n",
    "\n",
    "# Remove duplicate rows\n",
    "data = data.drop_duplicates()\n",
    "\n",
    "# Step 4: Convert non-numeric columns to numeric\n",
    "# Identify non-numeric columns\n",
    "non_numeric_columns = data.select_dtypes(include=['object']).columns.tolist()\n",
    "print(f\"Non-numeric columns: {non_numeric_columns}\")\n",
    "\n",
    "# Convert categorical columns to numeric using LabelEncoder\n",
    "label_encoders = {}\n",
    "for column in non_numeric_columns:\n",
    "    label_encoders[column] = LabelEncoder()\n",
    "    data[column] = label_encoders[column].fit_transform(data[column])\n",
    "\n",
    "# Step 5: Encode the target variable\n",
    "data['Disease'] = label_encoders['Disease'].fit_transform(data['Disease'])\n",
    "\n",
    "# Step 6: Check class distribution\n",
    "print(data['Disease'].value_counts())\n",
    "\n",
    "# Step 7: Feature selection\n",
    "# Check if the specified feature columns exist in the data\n",
    "feature_columns = [ 'S1','S2','S3','S4','S5']\n",
    "\n",
    "missing_features = [col for col in feature_columns if col not in data.columns]\n",
    "print(f\"Missing features: {missing_features}\")\n",
    "\n",
    "# Select only the existing features\n",
    "feature_columns = [col for col in feature_columns if col in data.columns]\n",
    "target_column = 'Disease'\n",
    "\n",
    "X = data[feature_columns]\n",
    "y = data[target_column]\n",
    "\n",
    "# Step 8: Split the data using stratified sampling\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Verify class distribution in training and test sets\n",
    "print(\"Training set class distribution:\")\n",
    "print(y_train.value_counts())\n",
    "print(\"Test set class distribution:\")\n",
    "print(y_test.value_counts())\n",
    "\n",
    "# Step 9: Normalize or scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Step 10: Train the logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Step 11: Evaluate the model\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "print(f'Classification Report:\\n{class_report}')\n",
    "\n",
    "# Step 12: Save the model\n",
    "joblib.dump(model, 'logistic_regression_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cf9d20-fe89-44ca-8ebd-3cec7186dc28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
